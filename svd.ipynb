{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a rank-deficient matrix W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2355,  0.1049,  0.0277,  0.2717, -0.1069,  0.3124,  0.2668,  0.1211,\n",
      "         -0.9132,  0.2465],\n",
      "        [ 0.8507,  0.5331,  0.0902,  0.5400, -0.4245,  1.0022,  1.0993,  0.4476,\n",
      "         -3.0183,  1.0352],\n",
      "        [-0.2607, -0.4673, -0.0085,  0.7045,  0.2058, -0.0584, -0.6039, -0.1573,\n",
      "          0.3727, -0.6024],\n",
      "        [-0.3829, -0.9508,  0.0042,  1.7915,  0.3681,  0.1304, -1.1195, -0.2485,\n",
      "          0.0672, -1.1328],\n",
      "        [ 0.1658,  1.1941, -0.0511, -3.0148, -0.3542, -0.6964,  1.1723,  0.1595,\n",
      "          1.3917,  1.2245],\n",
      "        [ 0.6174,  0.9482,  0.0301, -1.2144, -0.4478,  0.2682,  1.2910,  0.3620,\n",
      "         -1.1710,  1.2778],\n",
      "        [-0.8711, -0.3998, -0.1016, -0.9711,  0.3983, -1.1457, -0.9972, -0.4486,\n",
      "          3.3560, -0.9229],\n",
      "        [-0.7299, -0.7823, -0.0569,  0.4664,  0.4451, -0.5942, -1.2286, -0.4055,\n",
      "          1.9997, -1.1929],\n",
      "        [-0.5895, -0.9108, -0.0284,  1.1752,  0.4290, -0.2516, -1.2375, -0.3460,\n",
      "          1.1083, -1.2252],\n",
      "        [ 0.7297,  0.6084,  0.0679,  0.0306, -0.4017,  0.7359,  1.0757,  0.3939,\n",
      "         -2.3142,  1.0297]])\n"
     ]
    }
   ],
   "source": [
    "d, k = 10, 10\n",
    "\n",
    "# This way we can generate a rank-deficient matrix\n",
    "W_rank = 2\n",
    "W = torch.randn(d,W_rank) @ torch.randn(W_rank,k)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the rank of the matrix W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of W: 2\n"
     ]
    }
   ],
   "source": [
    "W_rank = np.linalg.matrix_rank(W)\n",
    "print(f'Rank of W: {W_rank}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the SVD decomposition of the W matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of B: torch.Size([10, 2])\n",
      "Shape of A: torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "# Perform SVD on W (W = UxSxV^T)\n",
    "U, S, V = torch.svd(W)\n",
    "\n",
    "# For rank-r factorization, keep only the first r singular values (and corresponding columns of U and V)\n",
    "U_r = U[:, :W_rank]\n",
    "S_r = torch.diag(S[:W_rank])\n",
    "V_r = V[:, :W_rank].t()  # Transpose V_r to get the right dimensions\n",
    "\n",
    "# Compute B = U_r * S_r and A = V_r\n",
    "B = U_r @ S_r\n",
    "A = V_r\n",
    "print(f'Shape of B: {B.shape}')\n",
    "print(f'Shape of A: {A.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the same input, check the output using the original W matrix and the matrices resulting from the decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y using W:\n",
      " tensor([ 0.1179, -3.5418,  2.4757,  5.2276, -5.0896, -6.7406,  5.7523,  5.8828,\n",
      "         5.4308, -5.6584])\n",
      "\n",
      "y' computed using BA:\n",
      " tensor([ 0.1179, -3.5418,  2.4757,  5.2276, -5.0896, -6.7406,  5.7523,  5.8828,\n",
      "         5.4308, -5.6584])\n"
     ]
    }
   ],
   "source": [
    "# Generate random bias and input\n",
    "bias = torch.randn(d)\n",
    "x = torch.randn(d)\n",
    "\n",
    "# Compute y = Wx + bias\n",
    "y = W @ x + bias\n",
    "# Compute y' = (B*A)x + bias\n",
    "y_prime = (B @ A) @ x + bias\n",
    "\n",
    "print(\"Original y using W:\\n\", y)\n",
    "print(\"\")\n",
    "print(\"y' computed using BA:\\n\", y_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters of W:  100\n",
      "Total parameters of B and A:  40\n"
     ]
    }
   ],
   "source": [
    "print(\"Total parameters of W: \", W.nelement())\n",
    "print(\"Total parameters of B and A: \", B.nelement() + A.nelement())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
